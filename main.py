import pandas as pd
import cv2
import re
import requests
from pathlib import Path
from tqdm import tqdm
from ultralytics import YOLO
import easyocr
import os

# ======================================================================
# PH·∫¶N 1: C·∫§U H√åNH V√Ä BI·∫æN TO√ÄN C·ª§C
# ======================================================================

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a t·∫•t c·∫£ k·∫øt qu·∫£ (t·ª± ƒë·ªông t·∫°o n·∫øu ch∆∞a c√≥)
RESULTS_DIR = Path("results")
RESULTS_DIR.mkdir(parents=True, exist_ok=True)

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a ·∫£nh bi·ªÉn s·ªë ƒë√£ c·∫Øt
CROPS_DIR = RESULTS_DIR / "crops"
CROPS_DIR.mkdir(parents=True, exist_ok=True)

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a ·∫£nh bi·ªÉn s·ªë ƒë√£ ti·ªÅn x·ª≠ l√Ω
PREPROC_DIR = RESULTS_DIR / "preproc"
PREPROC_DIR.mkdir(parents=True, exist_ok=True)

# T·∫£i m√¥ h√¨nh YOLOv8 pre-trained ƒë·ªÉ ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng
try:
    yolo_model = YOLO('yolov8n.pt')
except Exception as e:
    print(f"L·ªói khi t·∫£i m√¥ h√¨nh YOLO: {e}")
    yolo_model = None

# T·∫£i m√¥ h√¨nh EasyOCR (h·ªó tr·ª£ ti·∫øng Anh v√† ti·∫øng Vi·ªát)
try:
    ocr_reader = easyocr.Reader(['en', 'vi'], gpu=False) # ƒê·∫∑t gpu=True n·∫øu b·∫°n c√≥ GPU
except Exception as e:
    print(f"L·ªói khi t·∫£i m√¥ h√¨nh EasyOCR: {e}")
    ocr_reader = None

# ======================================================================
# PH·∫¶N 2: C√ÅC H√ÄM X·ª¨ L√ù CH√çNH
# ======================================================================

def detect_plates(image_path: str):
    """Ph√°t hi·ªán bi·ªÉn s·ªë trong ·∫£nh b·∫±ng YOLO v√† c·∫Øt c√°c bi·ªÉn s·ªë ra."""
    if not yolo_model:
        print("L·ªói: M√¥ h√¨nh YOLO kh√¥ng kh·∫£ d·ª•ng.")
        return []

    try:
        results = yolo_model(image_path, classes=[2, 3, 5, 7]) # L·ªçc c√°c class li√™n quan ƒë·∫øn xe
        detections = []
        for r in results:
            for box in r.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                conf = float(box.conf[0])
                cls = int(box.cls[0])

                img = cv2.imread(image_path)
                if img is None:
                    continue

                crop = img[y1:y2, x1:x2]
                
                # L∆∞u ·∫£nh ƒë√£ c·∫Øt
                filename = f"{Path(image_path).stem}_{x1}_{y1}.png"
                crop_path = CROPS_DIR / filename
                cv2.imwrite(str(crop_path), crop)
                
                detections.append({
                    "image_path": image_path,
                    "crop_path": str(crop_path),
                    "bbox": f"{x1},{y1},{x2},{y2}",
                    "confidence_yolo": conf,
                    "class_yolo": yolo_model.names[cls]
                })
        return detections
    except Exception as e:
        print(f"L·ªói khi ph√°t hi·ªán bi·ªÉn s·ªë: {e}")
        return []

def preprocess_plate(img):
    """H√†m ti·ªÅn x·ª≠ l√Ω ·∫£nh bi·ªÉn s·ªë: resize, tƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n v√† nh·ªã ph√¢n h√≥a."""
    try:
        # Resize ƒë·ªÉ chu·∫©n h√≥a ƒë·∫ßu v√†o
        img = cv2.resize(img, (200, 50))
        # Chuy·ªÉn sang ·∫£nh x√°m
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n
        enhanced = cv2.equalizeHist(gray)
        # Nh·ªã ph√¢n h√≥a (chuy·ªÉn sang ƒëen tr·∫Øng)
        _, bin_img = cv2.threshold(enhanced, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
        return enhanced, bin_img
    except Exception as e:
        print(f"L·ªói ti·ªÅn x·ª≠ l√Ω ·∫£nh: {e}")
        return None, None

def recognize_text(image):
    """Nh·∫≠n d·∫°ng vƒÉn b·∫£n t·ª´ ·∫£nh b·∫±ng EasyOCR."""
    if not ocr_reader:
        print("L·ªói: M√¥ h√¨nh EasyOCR kh√¥ng kh·∫£ d·ª•ng.")
        return "", 0.0
    
    try:
        results = ocr_reader.readtext(image)
        if results:
            # L·∫•y k·∫øt qu·∫£ v·ªõi ƒë·ªô tin c·∫≠y cao nh·∫•t
            best_result = max(results, key=lambda x: x[2])
            text, prob = best_result[1], best_result[2]
            return text, prob
        return "", 0.0
    except Exception as e:
        print(f"L·ªói khi nh·∫≠n d·∫°ng vƒÉn b·∫£n: {e}")
        return "", 0.0

def normalize_plate(raw_text: str) -> str:
    """Chu·∫©n h√≥a ƒë·ªãnh d·∫°ng bi·ªÉn s·ªë xe Vi·ªát Nam."""
    if not raw_text:
        return ""
    
    CONFUSION_MAP = {'O': '0', 'o': '0', 'I': '1', 'l': '1', '|': '1', 'S': '5', 'B': '8', 'Z': '2', 'D': '0'}
    
    # L√†m s·∫°ch k√Ω t·ª± v√† chuy·ªÉn ch·ªØ hoa
    text = "".join(CONFUSION_MAP.get(ch, ch) for ch in raw_text.upper())
    text = re.sub(r"[^A-Z0-9]", "", text)
    
    # Ch√®n d·∫•u g·∫°ch ngang sau m√£ t·ªânh (2 ho·∫∑c 3 s·ªë)
    m = re.match(r"^(\d{2,3})([A-Z])(\d+)$", text)
    if m:
        return f"{m.group(1)}-{m.group(2)}{m.group(3)}"
    return text

def send_to_backend(data: dict):
    """G·ª≠i d·ªØ li·ªáu k·∫øt qu·∫£ ƒë·∫øn m·ªôt API backend."""
    backend_url = "http://your-backend-api-url/api/process" # Thay th·∫ø b·∫±ng URL c·ªßa b·∫°n
    try:
        response = requests.post(backend_url, json=data)
        if response.status_code == 200:
            print("‚úîÔ∏è G·ª≠i d·ªØ li·ªáu th√†nh c√¥ng ƒë·∫øn backend.")
        else:
            print(f"‚ùå G·ª≠i d·ªØ li·ªáu th·∫•t b·∫°i. M√£ tr·∫°ng th√°i: {response.status_code}")
    except requests.exceptions.RequestException as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi ƒë·∫øn backend: {e}")

# ======================================================================
# PH·∫¶N 3: L∆ØU TR·ªÆ V√Ä XU·∫§T K·∫æT QU·∫¢
# ======================================================================

def run_pipeline(image_list: list):
    """Ch·∫°y to√†n b·ªô quy tr√¨nh t·ª´ ph√°t hi·ªán ƒë·∫øn chu·∫©n h√≥a v√† g·ª≠i d·ªØ li·ªáu."""
    all_results = []
    
    # B∆∞·ªõc 1: Ph√°t hi·ªán bi·ªÉn s·ªë
    print("üöó B∆∞·ªõc 1: ƒêang ph√°t hi·ªán bi·ªÉn s·ªë...")
    detection_rows = []
    for img_path in tqdm(image_list, desc="Ph√°t hi·ªán bi·ªÉn s·ªë"):
        detection_rows.extend(detect_plates(img_path))
    
    if not detection_rows:
        print("Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë n√†o.")
        return
        
    df_det = pd.DataFrame(detection_rows)
    df_det.to_csv(RESULTS_DIR / "detections.csv", index=False)
    print(f"‚úÖ ƒê√£ ph√°t hi·ªán v√† l∆∞u {len(detection_rows)} bi·ªÉn s·ªë.")
    
    # B∆∞·ªõc 2: Ti·ªÅn x·ª≠ l√Ω ·∫£nh bi·ªÉn s·ªë
    print("\nüñºÔ∏è B∆∞·ªõc 2: ƒêang ti·ªÅn x·ª≠ l√Ω ·∫£nh...")
    preproc_rows = []
    for row in tqdm(df_det.to_dict(orient="records"), desc="Ti·ªÅn x·ª≠ l√Ω ·∫£nh"):
        crop_path = Path(row["crop_path"])
        img = cv2.imread(str(crop_path))
        if img is None:
            continue
        
        enhanced, bin_img = preprocess_plate(img)
        if enhanced is None or bin_img is None:
            continue
            
        out_enh = PREPROC_DIR / f"{crop_path.stem}_enh.png"
        out_bin = PREPROC_DIR / f"{crop_path.stem}_bin.png"
        cv2.imwrite(str(out_enh), enhanced)
        cv2.imwrite(str(out_bin), bin_img)
        
        preproc_rows.append({
            **row,
            "enhanced_path": str(out_enh),
            "binary_path": str(out_bin),
        })
    df_preproc = pd.DataFrame(preproc_rows)
    df_preproc.to_csv(RESULTS_DIR / "preproc.csv", index=False)
    print(f"‚úÖ ƒê√£ ti·ªÅn x·ª≠ l√Ω {len(preproc_rows)} ·∫£nh.")

    # B∆∞·ªõc 3: Nh·∫≠n d·∫°ng vƒÉn b·∫£n OCR
    print("\nüìù B∆∞·ªõc 3: ƒêang nh·∫≠n d·∫°ng k√Ω t·ª± (OCR)...")
    ocr_rows = []
    for row in tqdm(df_preproc.to_dict(orient="records"), desc="Nh·∫≠n d·∫°ng OCR"):
        bin_img_path = row["binary_path"]
        img = cv2.imread(bin_img_path)
        if img is None:
            continue
            
        text_raw, conf_ocr = recognize_text(img)
        
        ocr_rows.append({
            **row,
            "text_raw": text_raw,
            "conf_ocr": conf_ocr,
        })
    df_ocr = pd.DataFrame(ocr_rows)
    df_ocr.to_csv(RESULTS_DIR / "ocr.csv", index=False)
    print(f"‚úÖ ƒê√£ nh·∫≠n d·∫°ng {len(ocr_rows)} bi·ªÉn s·ªë.")

    # B∆∞·ªõc 4: Chu·∫©n h√≥a d·ªØ li·ªáu
    print("\nüß≠ B∆∞·ªõc 4: ƒêang chu·∫©n h√≥a d·ªØ li·ªáu...")
    df_ocr["text_norm"] = df_ocr["text_raw"].apply(normalize_plate)
    df_ocr.to_csv(RESULTS_DIR / "normalized.csv", index=False)
    print(f"‚úÖ ƒê√£ chu·∫©n h√≥a {len(df_ocr)} k·∫øt qu·∫£.")
    
    # B∆∞·ªõc 5: G·ª≠i k·∫øt qu·∫£ cho backend
    print("\n‚¨ÜÔ∏è B∆∞·ªõc 5: ƒêang g·ª≠i d·ªØ li·ªáu ƒë·∫øn backend...")
    for index, row in tqdm(df_ocr.iterrows(), total=len(df_ocr), desc="G·ª≠i d·ªØ li·ªáu"):
        # T·∫°o m·ªôt dictionary v·ªõi c√°c d·ªØ li·ªáu c·∫ßn thi·∫øt ƒë·ªÉ g·ª≠i
        data_to_send = {
            "license_plate": row["text_norm"],
            "raw_text": row["text_raw"],
            "confidence": row["conf_ocr"],
            "image_path": row["image_path"],
            "bbox": row["bbox"],
        }
        send_to_backend(data_to_send)
    print("‚úÖ Ho√†n t·∫•t.")

# ======================================================================
# CH·∫†Y TH·ª¨ NGHI·ªÜM
# ======================================================================

if __name__ == '__main__':
    # THAY TH·∫æ DANH S√ÅCH N√ÄY B·∫∞NG C√ÅC ƒê∆Ø·ªúNG D·∫™N ƒê·∫æN ·∫¢NH C·ª¶A B·∫†N
    image_list = ["path/to/your/image1.jpg", "path/to/your/image2.png"]
    
    # T·∫°o m·ªôt th∆∞ m·ª•c ch·ª©a ·∫£nh demo n·∫øu ch∆∞a c√≥
    demo_dir = Path("demo_images")
    demo_dir.mkdir(exist_ok=True)
    
    # Th√™m m·ªôt ƒë∆∞·ªùng d·∫´n ·∫£nh gi·∫£ l·∫≠p ƒë·ªÉ ch·∫°y th·ª≠
    dummy_image_path = demo_dir / "car_demo.jpg"
    if not dummy_image_path.exists():
        print("T·∫°o m·ªôt file ·∫£nh gi·∫£ l·∫≠p ƒë·ªÉ ch·∫°y th·ª≠...")
        # B·∫°n c·∫ßn ph·∫£i c√≥ ·∫£nh ƒë·ªÉ thay th·∫ø v√†o ƒë√¢y. 
        # T·∫£i m·ªôt ·∫£nh demo v·ªÅ v√† ƒë·∫∑t t√™n l√† car_demo.jpg trong th∆∞ m·ª•c demo_images
        # D√πng google_search ƒë·ªÉ t√¨m ·∫£nh.
    
    image_list = [str(dummy_image_path)]
    
    run_pipeline(image_list)
